{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d96f5252-662e-4973-a882-40e3e794d892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crim       0\n",
      "zn         0\n",
      "indus      0\n",
      "chas       0\n",
      "nox        0\n",
      "rm         0\n",
      "age        0\n",
      "dis        0\n",
      "rad        0\n",
      "tax        0\n",
      "ptratio    0\n",
      "black      0\n",
      "lstat      0\n",
      "medv       0\n",
      "dtype: int64\n",
      "crim       0\n",
      "zn         0\n",
      "indus      0\n",
      "chas       0\n",
      "nox        0\n",
      "rm         0\n",
      "age        0\n",
      "dis        0\n",
      "rad        0\n",
      "tax        0\n",
      "ptratio    0\n",
      "black      0\n",
      "lstat      0\n",
      "dtype: int64\n",
      "异常值数量: 9\n",
      "异常值比例: 2.70%\n",
      "Epoch 1, Loss: 611.7552\n",
      "Epoch 11, Loss: 525.6938\n",
      "Epoch 21, Loss: 432.8469\n",
      "Epoch 31, Loss: 327.1600\n",
      "Epoch 41, Loss: 200.8491\n",
      "Epoch 51, Loss: 104.0177\n",
      "Epoch 61, Loss: 42.8302\n",
      "Epoch 71, Loss: 19.6672\n",
      "Epoch 81, Loss: 11.5043\n",
      "Epoch 91, Loss: 11.1980\n",
      "Epoch 101, Loss: 10.9779\n",
      "Epoch 111, Loss: 7.6141\n",
      "Epoch 121, Loss: 9.4869\n",
      "Epoch 131, Loss: 9.3116\n",
      "Epoch 141, Loss: 9.4097\n",
      "Epoch 151, Loss: 6.2439\n",
      "Epoch 161, Loss: 9.3153\n",
      "Epoch 171, Loss: 8.0015\n",
      "Epoch 181, Loss: 9.0845\n",
      "Epoch 191, Loss: 7.1990\n",
      "Epoch 201, Loss: 7.5598\n",
      "Epoch 211, Loss: 7.8753\n",
      "Epoch 221, Loss: 7.0776\n",
      "Epoch 231, Loss: 10.4523\n",
      "Epoch 241, Loss: 7.1264\n",
      "Epoch 251, Loss: 6.5398\n",
      "Epoch 261, Loss: 6.1060\n",
      "Epoch 271, Loss: 7.3714\n",
      "Epoch 281, Loss: 6.5177\n",
      "Epoch 291, Loss: 7.9486\n",
      "Epoch 301, Loss: 5.3599\n",
      "Epoch 311, Loss: 8.0811\n",
      "Epoch 321, Loss: 5.5025\n",
      "Epoch 331, Loss: 8.1486\n",
      "Epoch 341, Loss: 6.4855\n",
      "Epoch 351, Loss: 5.7154\n",
      "Epoch 361, Loss: 5.7324\n",
      "Epoch 371, Loss: 6.0292\n",
      "Epoch 381, Loss: 7.3362\n",
      "Epoch 391, Loss: 6.2321\n",
      "Epoch 401, Loss: 6.5356\n",
      "Epoch 411, Loss: 4.3871\n",
      "Epoch 421, Loss: 6.4533\n",
      "Epoch 431, Loss: 5.3806\n",
      "Epoch 441, Loss: 5.5910\n",
      "Epoch 451, Loss: 3.9824\n",
      "Epoch 461, Loss: 4.5468\n",
      "Epoch 471, Loss: 5.1578\n",
      "Epoch 481, Loss: 7.2861\n",
      "Epoch 491, Loss: 8.0906\n",
      "      ID       medv\n",
      "0      3  32.848804\n",
      "1      6  27.810133\n",
      "2      8  16.220560\n",
      "3      9  14.624740\n",
      "4     10  18.306347\n",
      "..   ...        ...\n",
      "168  496  23.011890\n",
      "169  497  19.823397\n",
      "170  499  22.037815\n",
      "171  501  19.270840\n",
      "172  505  21.194946\n",
      "\n",
      "[173 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#读取数据\n",
    "train1=pd.read_csv('C:/Users/31665/Downloads/boston-housing/train.csv')\n",
    "test1=pd.read_csv('C:/Users/31665/Downloads/boston-housing/test.csv')\n",
    "#删除一下ID列\n",
    "train = train1.iloc[:, 1:]\n",
    "test = test1.iloc[:, 1:] \n",
    "#查看数据的基本信息\n",
    "train.shape\n",
    "test.shape\n",
    "#看看数据是否有缺失值\n",
    "print(train.isnull().sum())\n",
    "print(test.isnull().sum())\n",
    "\n",
    "#检测异常值，使用IQR方法\n",
    "Q1 = train.quantile(0.25)\n",
    "Q3 = train.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "outliers = ((train < (Q1 - 1.5 * IQR)) | (train > (Q3 + 1.5* IQR))).any(axis=0)#any只要检测到异常便会false，axis=0表示对列检测\n",
    "num_outliers = outliers.sum()\n",
    "\n",
    "# 计算异常值比例\n",
    "total_samples = train.shape[0]\n",
    "outlier_ratio = (num_outliers / total_samples) * 100\n",
    "\n",
    "print(f\"异常值数量: {num_outliers}\")\n",
    "print(f\"异常值比例: {outlier_ratio:.2f}%\")\n",
    "\n",
    "train1 = train.copy()\n",
    "for col in train.columns[:-1]:# 遍历每个特征列除去最后一列\n",
    "    Q1, Q3 = train[col].quantile(0.25), train[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    # 用中位数替换超出范围的异常值，使用np.where，满足条件将异常值替换为中位数\n",
    "    median = train[col].median()\n",
    "    train1[col] = np.where(\n",
    "        (train[col] < lower_bound) | (train[col] > upper_bound),\n",
    "        median,  \n",
    "        train[col]\n",
    "    )\n",
    "\n",
    "#进行数据划分，x1将最后一列去除\n",
    "x1_data=train.iloc[:, :-1].values\n",
    "y1_data=train.medv.values\n",
    "x2_data=test.values\n",
    "\n",
    "#进行数据标准化\n",
    "scaler=StandardScaler()\n",
    "\n",
    "x1_data=scaler.fit_transform(x1_data)#只对测试集进行fit操作保证标准一样\n",
    "x2_data=scaler.transform(x2_data)\n",
    "#将数据转换为张量\n",
    "x1_data=torch.tensor(x1_data,dtype=torch.float32)\n",
    "x2_data=torch.tensor(x2_data,dtype=torch.float32)\n",
    "y1_data=torch.tensor(y1_data,dtype=torch.float32).view(-1,1)\n",
    "#将数据移到device上\n",
    "x1_data, x2_data, y1_data = x1_data.to(device), x2_data.to(device), y1_data.to(device)\n",
    "#使用dataset和dataloader\n",
    "train_data=Data.TensorDataset(x1_data,y1_data)\n",
    "train_loader=Data.DataLoader(dataset=train_data,\n",
    "                             batch_size=32,\n",
    "                             shuffle=True,\n",
    "                             drop_last=True,\n",
    "                             num_workers=0)\n",
    "#定义神经网络,定义了一个3层全连接\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.fc1=nn.Linear(13, 64)\n",
    "        self.bn1=nn.BatchNorm1d(64)#进行批归一化，加速收敛\n",
    "        self.fc2=nn.Linear(64, 32)\n",
    "        self.bn2=nn.BatchNorm1d(32)\n",
    "        self.fc3=nn.Linear(32, 1)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.3) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x=self.bn1(self.relu(self.fc1(x)))\n",
    "        x=self.dropout(x)\n",
    "        x=self.bn2(self.relu(self.fc2(x)))\n",
    "        x=self.fc3(x)\n",
    "        return x\n",
    "        \n",
    "\n",
    "model = Model().to(device)\n",
    "\n",
    "criterion = nn.MSELoss(reduction='mean')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "for epoch in range(500):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "\n",
    "        y_pred = model(batch_x)\n",
    "        loss = criterion(y_pred, batch_y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    \n",
    "    if epoch%10==0:\n",
    "        \n",
    "         print(f'Epoch {epoch + 1}, Loss: {running_loss / len(train_loader):.4f}')\n",
    "\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    \n",
    "    y_test_pred = model(x2_data)\n",
    "    y_test_pred = y_test_pred.cpu().numpy()\n",
    "    first_column = test1.iloc[:, 0].values\n",
    "\n",
    "    predictions_df = pd.DataFrame({\n",
    "        'ID': first_column,\n",
    "        'medv': y_test_pred.flatten()  \n",
    "    })\n",
    "\n",
    "    print(predictions_df)\n",
    "\n",
    "model.train()\n",
    "\n",
    "predictions_df.to_csv('predictions.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade036ed-54a1-4e17-af85-ee6dcb5ddcd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
