对于代码的解释都在代码文件里。  
官方代码感觉不太能看懂，便选了一个简化版。首先结果非常垃圾，一直在10%左右，还加了timm的预训练模型。可能有几个原因：加入预训练模型有问题，可能没加成功，导致CIFAR10如此小的数据集使得VIT没发挥出作用。在训练中没有完成微调等。  
选取的patch_size是4x4的，2x2也是可行的。对于数据集较小，选用传统的CNN准确率还是比较高。