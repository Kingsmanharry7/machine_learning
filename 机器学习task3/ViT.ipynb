{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fecd3c6-75e0-4f1d-8b27-f6f6af035c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch [1/10], Loss: 2.3096, Accuracy: 10.97%\n",
      "Epoch [2/10], Loss: 2.3101, Accuracy: 10.03%\n",
      "Epoch [3/10], Loss: 2.3079, Accuracy: 9.85%\n",
      "Epoch [4/10], Loss: 2.3061, Accuracy: 9.81%\n",
      "Epoch [5/10], Loss: 2.3052, Accuracy: 9.84%\n",
      "Epoch [6/10], Loss: 2.3041, Accuracy: 9.92%\n",
      "Epoch [7/10], Loss: 2.3037, Accuracy: 9.84%\n",
      "Epoch [8/10], Loss: 2.3036, Accuracy: 9.70%\n",
      "Epoch [9/10], Loss: 2.3031, Accuracy: 9.97%\n",
      "Epoch [10/10], Loss: 2.3031, Accuracy: 9.79%\n",
      "Accuracy of the model on the 10000 test images: 10.00%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import timm\n",
    "from torch import nn\n",
    "from einops import rearrange,repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "batch_size = 64\n",
    "learning_rate = 1e-4\n",
    "num_epochs = 10\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))#这里加了一个数据归一化\n",
    "])\n",
    " \n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='D:/Dataset/CIFAR-10', train=True, download=True, transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    " \n",
    "testset = torchvision.datasets.CIFAR10(root='D:/Dataset/CIFAR-10', train=False, download=True, transform=transform)\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "def pair(i):\n",
    "    return i if isinstance(i,tuple) else (i,i) \n",
    "\n",
    "\n",
    "class PreNorm(nn.Module):\n",
    "    def __init__(self,dim,fn):#接受不同函数\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(dim)#进行层归一化\n",
    "        self.fn = fn\n",
    "    def forward(self, x, **kwargs):#接受任意数量的参数以达到接受不同函数\n",
    "        return self.fn(self.norm(x), **kwargs)\n",
    "\n",
    "class FeedForward(nn.Module):#前馈\n",
    "    def __init__(self, dim, hidden_dim, dropout = 0.1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim, hidden_dim),\n",
    "            nn.GELU(),#使用Gelu激活函数\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, heads = 3, dim_head = 64, dropout = 0.1):\n",
    "        super().__init__()\n",
    "        inner_dim = dim_head *  heads\n",
    "        project_out = not (heads == 1 and dim_head == dim)\n",
    "\n",
    "        self.heads = heads\n",
    "        self.scale = dim_head ** -0.5 \n",
    "\n",
    "        self.attend = nn.Softmax(dim = -1)\n",
    "       \n",
    "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias = False)\n",
    "\n",
    "        self.to_out = nn.Sequential(\n",
    "            nn.Linear(inner_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        ) if project_out else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        qkv = self.to_qkv(x).chunk(3, dim = -1)\n",
    "        \n",
    "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = self.heads), qkv)\n",
    "\n",
    "        dots = torch.matmul(q, k.transpose(-1, -2)) * self.scale\n",
    "\n",
    "        attn = self.attend(dots)  \n",
    "\n",
    "        out = torch.matmul(attn, v)\n",
    "\n",
    "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
    "        return self.to_out(out)\n",
    "        \n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self,embed_dim,depth,heads,dim_head,mlp_dim,dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.layers=nn.ModuleList([])#存储一系列的模块\n",
    "        for _ in range(depth):\n",
    "            self.layers.append(nn.ModuleList([\n",
    "                PreNorm(embed_dim, Attention(embed_dim, heads = heads, dim_head = dim_head, dropout = dropout)),\n",
    "                PreNorm(embed_dim, FeedForward(embed_dim, mlp_dim, dropout = dropout))\n",
    "            ]))#每次新加attention和FeedForward层，共depth个\n",
    "    def forward(self, x):\n",
    "        for attention, feedforward in self.layers:  \n",
    "            x = attention(x) + x  \n",
    "            x = feedforward(x) + x#残差操作\n",
    "        return x\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ViT(nn.Module):\n",
    "    def __init__(self,*,image_size,patch_size,num_classes,embed_dim,depth,heads,mlp_dim,pool='cls',channels=3,dim_head=64,dropout=0.1,embed_dropout=0.1):\n",
    "        super().__init__()\n",
    "        image_height,image_width=pair(image_size)#成对赋值\n",
    "        patch_height,patch_width=pair(patch_size)\n",
    "\n",
    "        assert image_height%patch_height==0 and image_width%patch_width==0#保证image高度和宽度可以整除patch的高度和宽度\n",
    "\n",
    "        num_patches=(image_height//patch_height)*(image_width//patch_width)#计算有多少个patch\n",
    "\n",
    "        patch_dim=channels*patch_height*patch_width#计算patch维度\n",
    "        assert pool in {'cls', 'mean'}#输出时选择这个cls token或者用平均池化\n",
    "\n",
    "        self.to_patch_embedding = nn.Sequential(\n",
    "            Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1 = patch_height, p2 = patch_width),#转换维度，将batch_size，channels，height，width转换为batch_size,num_patches,patch_dim\n",
    "            nn.Linear(patch_dim, embed_dim),#进行线性映射\n",
    "        )\n",
    "\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, embed_dim))#进行位置信息嵌入计算，parameter表示可学习，randn为初始化，+1因为要加入cls_token\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, embed_dim))#定义cls，与每个patch维度相同。因为每个图块被展平了，所以变为了1x1x192\n",
    "        self.dropout = nn.Dropout(embed_dropout)\n",
    "\n",
    "        self.transformer = Transformer(embed_dim, depth, heads, dim_head, mlp_dim, dropout)#transfomer块\n",
    "\n",
    "        self.pool=pool\n",
    "        self.to_latent = nn.Identity()#占位符\n",
    "\n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.LayerNorm(embed_dim),\n",
    "            nn.Linear(embed_dim, num_classes)#线性层输出\n",
    "        )\n",
    "\n",
    "    def forward(self,image):\n",
    "        x=self.to_patch_embedding(image)\n",
    "        b, n, _ = x.shape#_表示不会显式使用\n",
    "\n",
    "        cls_tokens=repeat(self.cls_token, '() n d -> b n d', b = b)\n",
    "        x=torch.cat((cls_tokens, x), dim=1)\n",
    "        x+=self.pos_embedding[:, :(n + 1)]  \n",
    "        x=self.dropout(x)\n",
    "        x=self.transformer(x)\n",
    "        x = x.mean(dim = 1) if self.pool == 'mean' else x[:, 0]\n",
    "        x = self.to_latent(x)\n",
    "        return self.mlp_head(x)\n",
    "        \n",
    "pretrained_vit = timm.create_model('vit_base_patch16_224', pretrained=True)\n",
    "pretrained_state_dict = pretrained_vit.state_dict()\n",
    "\n",
    "model=ViT(\n",
    "    image_size=32,#图片大小\n",
    "    patch_size=4,#图块大小\n",
    "    num_classes=10,#最后要分类的数量\n",
    "    embed_dim=192,#patch embedding时的维度，即投射后的维度\n",
    "    depth=6,#transformer的个数，对于CIFAR10来说，这里数量更少，heads同理\n",
    "    heads=3,#自注意力头的数量\n",
    "    mlp_dim=768,#transformer后线形层升维后的维数，这里选择乘4\n",
    "    dropout=0.1,#丢弃神经元\n",
    "    embed_dropout=0.1).to(device)#embedding时丢弃\n",
    "\n",
    "pretrained_state_dict = {k: v for k, v in pretrained_state_dict.items() if k in model.state_dict() and model.state_dict()[k].shape == v.shape}\n",
    "model.load_state_dict(pretrained_state_dict, strict=False)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.999), weight_decay=0.1)\n",
    "\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    " \n",
    "            optimizer.zero_grad()\n",
    " \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    " \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    " \n",
    "            running_loss += loss.item()\n",
    " \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    " \n",
    "        accuracy = 100 * correct / total\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(trainloader):.4f}, Accuracy: {accuracy:.2f}%')\n",
    " \n",
    "def test():\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    " \n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy of the model on the 10000 test images: {accuracy:.2f}%')\n",
    " \n",
    "if __name__ == \"__main__\":\n",
    "    train()\n",
    "    test()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc51dd3a-f117-4e4f-9e02-6a2758da483a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a481e5-79c4-41d8-b51e-0c7cee6f7aa5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
