前提了解：  
1.计算机常使用矩阵存储和处理图像。因为图像是由一个个像素组成的，且组成的图形为矩形或正方形。灰度图像只包含黑白两种颜色，简单的可以用0，1来标注，即有图像的部分是1，其他部分是0.更详细的可以由0到255来表示，可以表示像素值的强度。对于彩色图片，首先彩色可以由三原色，红red，绿green，蓝blue组成，因此彩色图片可以由三个矩阵，RGB来表示，每个矩阵使用之前的0到255来表示。  
2.设计一个神经网络(整个模型)：1.确定输入与输出。确定输入是图像还是文本或其他数据，输出是什么类型的值。2.对数据进行处理。3.确定神经网络的结构。确定有多少层及隐藏层的数量和深度，每层的神经元数量，以及激活函数的设置和选择。4.根据模型选择损失函数。MSE等.5.选择优化器。SGD，Adam等。6.进行训练...
3.欠拟合：模型复杂度不够，精度很差，在训练数据就表现不好。过拟合：模型在训练集的表现很好，但对测试集的表现不好，泛化性不好。  


对于task2：  
首先了解到这种多分类问题再加上是彩色图片，用卷积比较好。于是开始便加了4层卷积看看效果，感觉不多也不少，卷积核设为比较常见的3x3，输出通道设定为16，32，64这样增长，2的倍数增长。再加上最大池化减少一下输出通道。最后再搞三个全连接层，最后降到10个通道。最后在forward中进行前馈，卷积+激活+池化。最后再加全连接。损失函数选择交叉熵，适配分类问题。优化器选择adam。主要按照教学视频来了一次，问题较少。主要问题是维度通道数的计算，最后解决就是直接等报错让计算机算再填就行。搜索了一下，进行了一些简单的优化，比如批归一化和丢弃一些神经元的操作。最后测试集结果大概是74%，训练最后是80%多。试了一下减少一层，训练集最后的准确率降低了，但测试集的准确率竟然还升了一小点。  
对于task_extra：  
首先是可视化，使用的是matplotlib和numpy。将losses和accuracy设置为空的一个组。在每次epoch完成时，记录一次，loss记录成平均loss，防止数量差距太大。设置一个epochs数组表示从1到epoch_num的每个数作为x轴。最后训练完后再打印出。    

提高准确率方面：首先用的是Inception，就是分成几个不同的卷积，算出结果，最后再拼接在一起。可以提高神经网络的深度和宽度的同时，减少过拟合的情况。使用的Inception模块是一个1个1x1，两个5x5，三个3x3和1个pool。网络部分加了三层卷积，用了两次Inception，和三层全连接。最后得到的结果是训练准确率达到了接近90%，但测试集的准确率却只提高了1%点几，可能有点过拟合，但dropout啥的都用了。  
再尝试了一下残差网络：残差部分用了两层卷积，再加上shortcut部分。shortcut部分在输入通道数与输出通道数不同时，可以达到跳跃的目的，更加缓解梯度消失。在神经网络部分加入了4层卷积，再经过4层残差，后面都是常规操作了。最后训练准确率可以达到90%多，测试集84%左右。  

  

用的是jupyter notebook，保存文件后它把代码结果啥的都放在代码后面了



